{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659600e6",
   "metadata": {},
   "source": [
    "# Patent classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f73403",
   "metadata": {},
   "source": [
    "To begin with, we generate a tiny artificial dataset with 4 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"This is machine learning related patent\", \"This is a biology related patent\", \"This is machine learning related patent\", \"This is a biology related patent\"]\n",
    "labels = [\"Machine learning\", \"Biology\", \"Machine learning\", \"Biology\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf5cd0",
   "metadata": {},
   "source": [
    "All the classifiers require the labels to be integers. For this reason, the `LabelsConverter` class can be used to do the needed conversions. The `encode_labels` method converts string labels to int while the `decode_labels` method does the opposite. The latter could be useful to convert the output of the predictions to the more meaningful existing label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f753f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dapc.labels_converter import LabelsConverter\n",
    "\n",
    "lb = LabelsConverter(labels)\n",
    "lb.classes\n",
    "\n",
    "labels_int = lb.encode_labels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca3bb7",
   "metadata": {},
   "source": [
    "The simpliest way to train a patent classier is to instantiate a Classifier by specifying the classifier type and its parameters.\n",
    "\n",
    "Below we instantiate one classifier for each of the available categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ecd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dapc.classifier import Classifier\n",
    "\n",
    "transformer_classifier = model = Classifier(\"transformers\", model_name=\"bert-base-uncased\", num_of_labels=len(lb.classes))\n",
    "adapter_classifier = Classifier(\"adapters\", model_name=\"bert-base-uncased\", num_of_labels=len(lb.classes))\n",
    "trans_cnn_classifier = Classifier(\"transformers_cnn\", model_name=\"bert-base-uncased\", num_of_labels=len(lb.classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4887dcf4",
   "metadata": {},
   "source": [
    "All the above classifiers use the default configuration that the respective models hold (Check their implementation for further details). The use of a custom model is also permitted. In this case, someone should initialize the custom model and then pass it directly to the classifier. The example below depicts the instantiation of a custom transformer model with different learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176dc400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dapc.models.transformer_classifier import TransformerClassifier\n",
    "transformer_custom_model = TransformerClassifier(classes=3, learning_rate=5e-5)\n",
    "transformer_classifier_custom = Classifier(transformer_custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c65f38",
   "metadata": {},
   "source": [
    "Let's focus on the transformer_classifier and train it using our tiny example dataset. In order to train a classifier we need to provide a list of texts, the respective list of labels and the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_classifier.train(texts,labels_int, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cee5ec",
   "metadata": {},
   "source": [
    "The accuracy is zero as the dataset is dummy but let's pretend that the model has been trained succesfully and we would like to evaluate it. This can be done by using the `evaluate` method and passing to it a set of texts and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836bf4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_classifier.evaluate(texts,labels_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5280b2b",
   "metadata": {},
   "source": [
    "Respectively for prediction, we can use the `predict` method and providing the list of texts of interest. The output of the prediction is the predicted labels together with the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, logits = transformer_classifier.predict(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4127401",
   "metadata": {},
   "source": [
    "Let's use the decode_labels methood to convert the labels to their names and inspect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894137f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.decode_labels(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f29852",
   "metadata": {},
   "source": [
    "To cross validate the classifier, someone can use the `cross_validation` method. In addition to the texts,labels and epochs, number of cross validations(k) should also be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_classifier.cross_validation(texts,labels_int,k=2,epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456319b2",
   "metadata": {},
   "source": [
    "Once the training is done, we can save the model using the `save` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f15b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_classifier.save(\"my_beatiful_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2539347",
   "metadata": {},
   "source": [
    "Then you can reload it using the `load` method and use it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_classifier.load(\"my_beatiful_classifier\")\n",
    "transformer_classifier.evaluate(texts,labels_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8b9d3",
   "metadata": {},
   "source": [
    "Note that as during cross validation more than one models are trained, we suggest to not use the save method after the cross validation. Instead you can define a save model strategy during the cross validation by using the `save_model_path` and `save_model_strategy` parameters of the cross_validation method. Specifically `save_model_path` defines the path where the checkpoins will be saved while the `save_model_strategy` defines the strategy based on which they are going to be saved. For instance, if someone wishes to store all the models then should define `save_model_strategy='all'`. Alternative, if the goal is to save the best model based on a specific metric then the name of the metric should be provided, for example:  `save_model_strategy='micro_f1_score'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b56f6",
   "metadata": {},
   "source": [
    "### Multilingual patent classification\n",
    "\n",
    "The package supports multilingual training. All the information that have been presented in the monolingual notebook stand also for this case. The only addition that the multilingual classifier holds is the ability to perform per language evaluation of the model's performance.\n",
    "\n",
    "Firstly, let's create an instance of the multilingual classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dapc.classifier_multilingual import ClassifierMultilingual\n",
    "\n",
    "transformer_classifier_multi = ClassifierMultilingual(\"transformers\", model_name=\"bert-base-uncased\", num_of_labels=len(lb.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5e861",
   "metadata": {},
   "source": [
    "Then, let's stick on the already existing small dataset and consider that it is a multilingual dataset. For a multilingual evaluation, we need a list of languages of the input texts. If we do not have this inforation available already, the package contains the LanguageDetector class to do this for you relying on spacy. \n",
    "\n",
    "<u>Note: before running the language detector for the first time execute the following command to download the needed model:\n",
    "`python -m spacy download en_core_web_sm`!</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4316b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dapc.languages_detector import LanguagesDetector\n",
    "\n",
    "lan_detector = LanguagesDetector()\n",
    "langs = lan_detector.infer_languages(texts)\n",
    "langs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8257ace",
   "metadata": {},
   "source": [
    "Once the training set and their languages are known, we can train the model or use the multilingual cross validation and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_classifier_multi.cross_validation_multilingual(texts,labels_int, langs,k=2,epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
